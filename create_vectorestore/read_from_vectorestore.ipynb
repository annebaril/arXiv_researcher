{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135977/1845895763.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
      "/home/barilanne076/.pyenv/versions/arxiv_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_135977/1845895763.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored Documents:\n",
      "ID: da3370a8-8c44-4645-821c-0aa1d19598a0 → Document: Consistent Subject Generation via Contrastive Instantiated Concepts: While text-to-image generative models can synthesize diverse and faithful\n",
      "contents, subject variation across multiple creations limits the application in\n",
      "long content generation. Existing approaches require time-consuming tuning,\n",
      "references for all subjects, or access to other creations. We introduce\n",
      "Contrastive Concept Instantiation (CoCoIns) to effectively synthesize\n",
      "consistent subjects across multiple independent creations. The framework\n",
      "consists of a generative model and a mapping network, which transforms input\n",
      "latent codes into pseudo-words associated with certain instances of concepts.\n",
      "Users can generate consistent subjects with the same latent codes. To construct\n",
      "such associations, we propose a contrastive learning approach that trains the\n",
      "network to differentiate the combination of prompts and latent codes. Extensive\n",
      "evaluations of human faces with a single subject show that CoCoIns performs\n",
      "comparably to existing methods while maintaining higher flexibility. We also\n",
      "demonstrate the potential of extending CoCoIns to multiple subjects and other\n",
      "object categories.\n",
      "ID: 4c0757a1-fa24-4c1c-8004-594d92428d00 → Document: The fundamental localization phases in quasiperiodic systems: A unified\n",
      "  framework and exact results: The disordered quantum systems host three types of quantum states, the\n",
      "extended, localized, and critical, which bring up various distinct fundamental\n",
      "phases, including the pure phases and coexisting ones with mobility edges. The\n",
      "quantum phases involving critical states are of particular importance, but are\n",
      "less understood compared with the other ones, and the different phases have\n",
      "been separately studied in different quasiperiodic models. Here we propose a\n",
      "unified framework based on a spinful quasiperiodic system which unifies the\n",
      "realizations of all the fundamental Anderson phases, %with or without mobility\n",
      "edges, with the exact and universal results being obtained for these distinct\n",
      "phases. Through the duality transformation and renormalization group method, we\n",
      "show that the pure phases are obtained when the (emergent) chiral symmetry\n",
      "preserves in the proposed spin-1/2 quasiperiodic model, which provides a\n",
      "criteria for the emergence of the pure phases or the coexisting ones with\n",
      "mobility edges. Further, we uncover a new universal mechanism for the critical\n",
      "states that the emergence of such states is protected by the generalized\n",
      "incommensurate matrix element zeros in the spinful quasiperiodic model, as a\n",
      "novel generalization of the quasiperiodic hopping zeros in the spinless\n",
      "systems. We also show with the Avila's global theory the criteria of exact\n",
      "solvability for the present unified quasiperiodic system, with which we\n",
      "identify several new quasiperiodic models derived from the spinful system\n",
      "hosting exactly solvable Anderson phases. In particular, we reach a single\n",
      "model that hosts all the seven fundamental phases of Anderson localization.\n",
      "Finally, an experimental scheme is proposed to realize these models using\n",
      "quasiperiodic optical Raman lattices.\n",
      "ID: 36a46ec2-6862-4b94-9107-d95fce23ba08 → Document: ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning: The ACPBench dataset provides atomic reasoning tasks required for efficient\n",
      "planning. The dataset is aimed at distilling the complex plan generation task\n",
      "into separate atomic reasoning tasks in their easiest possible form, boolean or\n",
      "multiple-choice questions, where the model has to choose the right answer from\n",
      "the provided options. While the aim of ACPBench is to test the simplest form of\n",
      "reasoning about action and change, when tasked with planning, a model does not\n",
      "typically have options to choose from and thus the reasoning required for\n",
      "planning dictates an open-ended, generative form for these tasks. To that end,\n",
      "we introduce ACPBench Hard, a generative version of ACPBench, with open-ended\n",
      "questions which the model needs to answer. Models that perform well on these\n",
      "tasks could in principle be integrated into a planner or be used directly as a\n",
      "policy. We discuss the complexity of these tasks as well as the complexity of\n",
      "validating the correctness of their answers and present validation algorithms\n",
      "for each task. Equipped with these validators, we test the performance of a\n",
      "variety of models on our tasks and find that for most of these tasks the\n",
      "performance of even the largest models is still subpar. Our experiments show\n",
      "that no model outperforms another in these tasks and with a few exceptions all\n",
      "tested language models score below 65%, indicating that even the current\n",
      "frontier language models have a long way to go before they can reliably reason\n",
      "about planning. In fact, even the so-called reasoning models struggle with\n",
      "solving these reasoning tasks. ACPBench Hard collection is available at the\n",
      "following link: https://ibm.github.io/ACPBench\n",
      "ID: fc1bc0c8-f460-4711-a4c3-f29aa20d5eb4 → Document: Transverse orbital angular momentum: setting the record straight: The nature of the transverse orbital angular momentum (tOAM) associated with\n",
      "spatiotemporal optical vortex (STOV) pulses has been the subject of recent\n",
      "debate. We demonstrate that the approaches to tOAM presented in several recent\n",
      "papers are incorrect and lead to unphysical results, including erroneous claims\n",
      "of zero total tOAM. We emphasize the importance of calculating the OAM of any\n",
      "extended physical object at a common instant of time, and reemphasize the\n",
      "special status of the centre of energy as a reference point for all OAM\n",
      "calculations. The theory presented in [Phys. Rev. Lett. 127, 193901 (2021)] is\n",
      "the only correct classical field-based framework that both agrees with\n",
      "experiments and provides a self consistent understanding of transverse OAM in\n",
      "spatiotemporal light fields.\n",
      "ID: a3412c3c-df57-4e95-be65-27372f0bfde4 → Document: Unveiling the Fast Acceleration of AGN-Driven Winds at Kiloparsec Scales: Supermassive black holes at the centre of galaxies gain mass through\n",
      "accretion disks. Models predict that quasi-spherical winds, expelled by the\n",
      "black hole during active accretion phases, have a key role in shaping galaxy\n",
      "evolution by regulating star formation, the distribution of metals over\n",
      "kiloparsec scales, and by sweeping ambient gas to the outskirts and beyond of\n",
      "galaxies. Nonetheless, the mechanism driving these outflows and the amount of\n",
      "energy exchanged between the wind and the galaxy's interstellar medium remain\n",
      "unclear. Here, we present a detailed analysis of the kinematical properties of\n",
      "winds in a sample of nearby active galaxies using the novel kinematic tool\n",
      "MOKA3D, which takes into account the clumpy nature of the ISM. We find\n",
      "remarkable similarities among the properties of the outflows in all the\n",
      "galaxies examined. In particular, we provide the first evidence that outflows\n",
      "exhibit a regular trend in radial velocity, initially constant or slightly\n",
      "decreasing, followed by rapid acceleration starting at approximately 1 kpc from\n",
      "the nucleus, despite the seemingly complex kinematics observed. The observed\n",
      "behavior aligns with our current theoretical understanding of Active Galactic\n",
      "Nuclei outflows, where a momentum-driven phase transitions to an\n",
      "energy-conserving phase just beyond approximately 1 kpc. The constant velocity\n",
      "of the momentum-driven wind is then rapidly accelerated following the\n",
      "inefficient Compton cooling of post-shock material and the transition to energy\n",
      "conservation. The measured radial terminal velocities of the outflows are\n",
      "always larger than the escape velocities from the host galaxies, confirming the\n",
      "key role of outflows in shaping the galaxy properties and evolution, as a\n",
      "manifestation of AGN feedback. Our results, only made possible by our novel\n",
      "kinematic analysis tool, are crucial to understand the origin and the powering\n",
      "mechanism of these winds.\n",
      "ID: fb272c60-b5c6-4ffa-aa44-5aa222c4502a → Document: Modified cosmology though spacetime thermodynamics and generalized\n",
      "  mass-to-horizon entropy: In this work we apply the gravity-thermodynamics approach for the case of\n",
      "generalized mass-to-horizon entropy, which is a two-parameter extension of\n",
      "Bekenstein-Hawking entropy that arises from the extended mass-to-horizon\n",
      "relation, that is in turn required in order to have consistency with the\n",
      "Clausius relation. We extract the modified Friedmann equations and we obtain an\n",
      "effective dark energy sector arising from the novel terms. We derive analytical\n",
      "solutions for the dark energy density parameter, the dark energy\n",
      "equation-of-state parameter, and the deceleration parameter, and we show that\n",
      "the Universe exhibits the usual thermal history with the succession of matter\n",
      "and dark energy epochs. Additionally, depending on the value of the entropy\n",
      "parameters, the dark energy equation-of-state parameter can either lie in the\n",
      "phantom regime at high redshifts entering into the quintessence regime at small\n",
      "redshifts, or it can lie in the quintessence regime at high redshifts and\n",
      "experience the phantom-divide crossing at small redshifts, while in the far\n",
      "future in all cases it asymptotically obtains the cosmological constant value\n",
      "$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n",
      "(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\n",
      "datasets, showing that the scenario is in agreement with observations.\n",
      "ID: 88dfbe72-c863-4896-b144-4d2c87056b39 → Document: Spontaneous Emission from Electronic Metastable Resonance States: We demonstrate that calculating the spontaneous emission decay rate from\n",
      "metastable resonance states (states with finite lifetimes embedded in the\n",
      "continuum) requires considering transitions to all continuum states, not just\n",
      "to lower states. This holds even when the lifetimes of the metastable states\n",
      "are very long and might be effectively considered as bound states in the\n",
      "continuum. However, employing complex-scaling transformations, this\n",
      "computationally prohibitive task becomes feasible by utilizing methods\n",
      "originally designed for excited bound states for calculation of complex poles\n",
      "of the scattering matrix. As an illustrative example, these methods are applied\n",
      "to calculate the spontaneous emission decay rates of metastable resonance\n",
      "states in a double-barrier potential. The rapid numerical convergence of this\n",
      "approach highlights a new avenue for studying spontaneous emission from\n",
      "metastable states in real-life systems, particularly in many-electron systems,\n",
      "where calculation of the spontaneous emission decay rate from metastable\n",
      "resonances (e.g., autoionization states) is computationally difficult, if not\n",
      "impossible, using the standard (Hermitian) formalism of quantum mechanics.\n",
      "ID: 05ed4db1-6d4e-4d24-bfcf-13c0183043d0 → Document: On Speedups for Convex Optimization via Quantum Dynamics: We explore the potential for quantum speedups in convex optimization using\n",
      "discrete simulations of the Quantum Hamiltonian Descent (QHD) framework, as\n",
      "proposed by Leng et al., and establish the first rigorous query complexity\n",
      "bounds. We develop enhanced analyses for quantum simulation of Schr\\\"odinger\n",
      "operators with black-box potential via the pseudo-spectral method, providing\n",
      "explicit resource estimates independent of wavefunction assumptions. These\n",
      "bounds are applied to assess the complexity of optimization through QHD. Our\n",
      "findings pertain to unconstrained convex optimization in $d$ dimensions. In\n",
      "continuous time, we demonstrate that QHD, with suitable parameters, can achieve\n",
      "arbitrarily fast convergence rates. The optimization speed limit arises solely\n",
      "from the discretization of the dynamics, mirroring a property of the classical\n",
      "dynamics underlying QHD. Considering this cost, we show that a $G$-Lipschitz\n",
      "convex function can be optimized to an error of $\\epsilon$ with\n",
      "$\\widetilde{\\mathcal{O}}(d^{1.5}G^2 R^2/\\epsilon^2)$ queries. Moreover, under\n",
      "reasonable assumptions on the complexity of Hamiltonian simulation,\n",
      "$\\widetilde{\\Omega}(d/\\epsilon^2)$ queries are necessary. Thus, QHD does not\n",
      "offer a speedup over classical zeroth order methods with exact oracles.\n",
      "However, we demonstrate that the QHD algorithm tolerates\n",
      "$\\widetilde{\\mathcal{O}}(\\epsilon^3/d^{1.5}G^2 R^2)$ noise in function\n",
      "evaluation. We show that QHD offers a super-quadratic query advantage over all\n",
      "known classical algorithms tolerating this level of evaluation noise in the\n",
      "high-dimension regime. Additionally, we design a quantum algorithm for\n",
      "stochastic convex optimization that provides a super-quadratic speedup over all\n",
      "known classical algorithms in the high-dimension regime. To our knowledge,\n",
      "these results represent the first rigorous quantum speedups for convex\n",
      "optimization achieved through a dynamical algorithm.\n",
      "ID: eab94874-8365-4f28-8711-299e0fafd0a6 → Document: Contextual Preference Collaborative Measure Framework Based on Belief\n",
      "  System: To reduce the human intervention in the preference measure process,this\n",
      "article proposes a preference collaborative measure framework based on an\n",
      "updated belief system,which is also capable of improving the accuracy and\n",
      "efficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\n",
      "the average internal distance of rulesets are proposed for specifying the\n",
      "relationship between the rules.For discovering the most representative\n",
      "preferences that are common in all users,namely common preference,a algorithm\n",
      "based on average internal distance of ruleset,PRA algorithm,is proposed,which\n",
      "aims to finish the discoveryprocess with minimum information loss\n",
      "rate.Furthermore,the concept of Common belief is proposed to update the belief\n",
      "system,and the common preferences are the evidences of updated belief\n",
      "system.Then,under the belief system,the proposed belief degree and deviation\n",
      "degree are used to determine whether a rule confirms the belief system or not\n",
      "and classify the preference rules into two kinds(generalized or\n",
      "personalized),and eventually filters out Top-K interesting rules relying on\n",
      "belief degree and deviation degree.Based on above,a scalable interestingness\n",
      "calculation framework that can apply various formulas is proposed for\n",
      "accurately calculating interestingness in different conditions.At last,IMCos\n",
      "algorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\n",
      "and efficiency of the framework by using weighted cosine similarity and\n",
      "correlation coefficients as belief degree.In experiments,the proposed\n",
      "algorithms are compared to two state-of-the-art algorithms and the results show\n",
      "that IMCos and IMCov outperform than the other two in most aspects.\n",
      "ID: efcd180c-c6c2-4391-abab-c80f27b62ed5 → Document: Sample-Optimal Private Regression in Polynomial Time: We consider the task of privately obtaining prediction error guarantees in\n",
      "ordinary least-squares regression problems with Gaussian covariates (with\n",
      "unknown covariance structure). We provide the first sample-optimal polynomial\n",
      "time algorithm for this task under both pure and approximate differential\n",
      "privacy. We show that any improvement to the sample complexity of our algorithm\n",
      "would violate either statistical-query or information-theoretic lower bounds.\n",
      "Additionally, our algorithm is robust to a small fraction of arbitrary outliers\n",
      "and achieves optimal error rates as a function of the fraction of outliers. In\n",
      "contrast, all prior efficient algorithms either incurred sample complexities\n",
      "with sub-optimal dimension dependence, scaling with the condition number of the\n",
      "covariates, or obtained a polynomially worse dependence on the privacy\n",
      "parameters.\n",
      "  Our technical contributions are two-fold: first, we leverage resilience\n",
      "guarantees of Gaussians within the sum-of-squares framework. As a consequence,\n",
      "we obtain efficient sum-of-squares algorithms for regression with optimal\n",
      "robustness rates and sample complexity. Second, we generalize the recent\n",
      "robustness-to-privacy framework [HKMN23, (arXiv:2212.05015)] to account for the\n",
      "geometry induced by the covariance of the input samples. This framework\n",
      "crucially relies on the robust estimators to be sum-of-squares algorithms, and\n",
      "combining the two steps yields a sample-optimal private regression algorithm.\n",
      "We believe our techniques are of independent interest, and we demonstrate this\n",
      "by obtaining an efficient algorithm for covariance-aware mean estimation, with\n",
      "an optimal dependence on the privacy parameters.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Load the stored vector database\n",
    "vectorstore = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
    "\n",
    "# Retrieve all stored documents\n",
    "data = vectorstore.get()\n",
    "\n",
    "print(\"Stored Documents:\")\n",
    "for doc_id, content in zip(data[\"ids\"], data[\"documents\"]):\n",
    "    print(f\"ID: {doc_id} → Document: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
