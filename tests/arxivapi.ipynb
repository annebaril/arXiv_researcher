{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arxiv # https://pypi.org/project/arxiv/\n",
    "from os import environ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching results\n",
    "def search_arxiv(query, max_results=10):\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        results.append({\n",
    "            \"title\": result.title,\n",
    "            \"summary\": result.summary,\n",
    "            \"authors\": [a.name for a in result.authors],\n",
    "            \"url\": result.entry_id\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41969/3025636481.py:8: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trustworthy and Efficient LLMs Meet Databases http://arxiv.org/abs/2412.18022v1\n",
      "Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications http://arxiv.org/abs/2406.10300v1\n",
      "Parrot: Efficient Serving of LLM-based Applications with Semantic Variable http://arxiv.org/abs/2405.19888v1\n",
      "A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends http://arxiv.org/abs/2311.10372v2\n",
      "LLM Online Spatial-temporal Signal Reconstruction Under Noise http://arxiv.org/abs/2411.15764v1\n",
      "What Limits LLM-based Human Simulation: LLMs or Our Design? http://arxiv.org/abs/2501.08579v1\n",
      "Asynchronous LLM Function Calling http://arxiv.org/abs/2412.07017v1\n",
      "Multi-LLM Text Summarization http://arxiv.org/abs/2412.15487v1\n",
      "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications http://arxiv.org/abs/2404.14809v1\n",
      "Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates http://arxiv.org/abs/2408.13006v2\n"
     ]
    }
   ],
   "source": [
    "papers = search_arxiv(\"LLM\")\n",
    "for paper in papers:\n",
    "    print(paper[\"title\"], paper[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41969/2525196581.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "/home/barilanne076/.pyenv/versions/arxiv_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for paper in papers:\n",
    "    content = f\"title: {paper['title']} \\n Summary: {paper['summary']}\"\n",
    "    docs.append(content)\n",
    "\n",
    "vectorstore = Chroma.from_texts(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7f2b21f9fe20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series \n",
      " Summary: This work summarizes two ways to accomplish Time-Series (TS) tasks in today's\n",
      "Large Language Model (LLM) context: LLM-for-TS (model-centric) designs and\n",
      "trains a fundamental large model, or fine-tunes a pre-trained LLM for TS data;\n",
      "TS-for-LLM (data-centric) converts TS into a model-friendly representation to\n",
      "enable the pre-trained LLM to handle TS data. Given the lack of data, limited\n",
      "resources, semantic context requirements, and so on, this work focuses on\n",
      "TS-for-LLM, where we aim to activate LLM's ability for TS data by designing a\n",
      "TS embedding method suitable for LLM. The proposed method is named TEST. It\n",
      "first tokenizes TS, builds an encoder to embed TS via instance-wise,\n",
      "feature-wise, and text-prototype-aligned contrast, where the TS embedding space\n",
      "is aligned to LLM embedding layer space, then creates soft prompts to make LLM\n",
      "more open to that embeddings, and finally implements TS tasks using the frozen\n",
      "LLM. We also demonstrate the feasibility of TS-for-LLM through theory and\n",
      "experiments. Experiments are carried out on TS classification, forecasting, and\n",
      "representation tasks using eight frozen LLMs with various structures and sizes.\n",
      "The results show that the pre-trained LLM with TEST strategy can achieve better\n",
      "or comparable performance than today's SOTA TS models and offer benefits for\n",
      "few-shot and generalization. By treating LLM as the pattern machine, TEST can\n",
      "endow LLM's ability to process TS data without compromising language ability.\n",
      "We hope that this study will serve as a foundation for future work to support\n",
      "TS+LLM progress.\n",
      "\n",
      "\n",
      "title: Parrot: Efficient Serving of LLM-based Applications with Semantic Variable \n",
      " Summary: The rise of large language models (LLMs) has enabled LLM-based applications\n",
      "(a.k.a. AI agents or co-pilots), a new software paradigm that combines the\n",
      "strength of LLM and conventional software. Diverse LLM applications from\n",
      "different tenants could design complex workflows using multiple LLM requests to\n",
      "accomplish one task. However, they have to use the over-simplified\n",
      "request-level API provided by today's public LLM services, losing essential\n",
      "application-level information. Public LLM services have to blindly optimize\n",
      "individual LLM requests, leading to sub-optimal end-to-end performance of LLM\n",
      "applications.\n",
      "  This paper introduces Parrot, an LLM service system that focuses on the\n",
      "end-to-end experience of LLM-based applications. Parrot proposes Semantic\n",
      "Variable, a unified abstraction to expose application-level knowledge to public\n",
      "LLM services. A Semantic Variable annotates an input/output variable in the\n",
      "prompt of a request, and creates the data pipeline when connecting multiple LLM\n",
      "requests, providing a natural way to program LLM applications. Exposing\n",
      "Semantic Variables to the public LLM service allows it to perform conventional\n",
      "data flow analysis to uncover the correlation across multiple LLM requests.\n",
      "This correlation opens a brand-new optimization space for the end-to-end\n",
      "performance of LLM-based applications. Extensive evaluations demonstrate that\n",
      "Parrot can achieve up to an order-of-magnitude improvement for popular and\n",
      "practical use cases of LLM applications.\n",
      "\n",
      "\n",
      "title: Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications \n",
      " Summary: Large Language Models (LLMs) have become widely adopted recently. Research\n",
      "explores their use both as autonomous agents and as tools for software\n",
      "engineering. LLM-integrated applications, on the other hand, are software\n",
      "systems that leverage an LLM to perform tasks that would otherwise be\n",
      "impossible or require significant coding effort. While LLM-integrated\n",
      "application engineering is emerging as new discipline, its terminology,\n",
      "concepts and methods need to be established. This study provides a taxonomy for\n",
      "LLM-integrated applications, offering a framework for analyzing and describing\n",
      "these systems. It also demonstrates various ways to utilize LLMs in\n",
      "applications, as well as options for implementing such integrations.\n",
      "  Following established methods, we analyze a sample of recent LLM-integrated\n",
      "applications to identify relevant dimensions. We evaluate the taxonomy by\n",
      "applying it to additional cases. This review shows that applications integrate\n",
      "LLMs in numerous ways for various purposes. Frequently, they comprise multiple\n",
      "LLM integrations, which we term ``LLM components''. To gain a clear\n",
      "understanding of an application's architecture, we examine each LLM component\n",
      "separately. We identify thirteen dimensions along which to characterize an LLM\n",
      "component, including the LLM skills leveraged, the format of the output, and\n",
      "more. LLM-integrated applications are described as combinations of their LLM\n",
      "components. We suggest a concise representation using feature vectors for\n",
      "visualization.\n",
      "  The taxonomy is effective for describing LLM-integrated applications. It can\n",
      "contribute to theory building in the nascent field of LLM-integrated\n",
      "application engineering and aid in developing such systems. Researchers and\n",
      "practitioners explore numerous creative ways to leverage LLMs in applications.\n",
      "Though challenges persist, integrating LLMs may revolutionize the way software\n",
      "systems are built.\n",
      "\n",
      "\n",
      "title: Trustworthy and Efficient LLMs Meet Databases \n",
      " Summary: In the rapidly evolving AI era with large language models (LLMs) at the core,\n",
      "making LLMs more trustworthy and efficient, especially in output generation\n",
      "(inference), has gained significant attention. This is to reduce plausible but\n",
      "faulty LLM outputs (a.k.a hallucinations) and meet the highly increased\n",
      "inference demands. This tutorial explores such efforts and makes them\n",
      "transparent to the database community. Understanding these efforts is essential\n",
      "in harnessing LLMs in database tasks and adapting database techniques to LLMs.\n",
      "Furthermore, we delve into the synergy between LLMs and databases, highlighting\n",
      "new opportunities and challenges in their intersection. This tutorial aims to\n",
      "share with database researchers and practitioners essential concepts and\n",
      "strategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining\n",
      "in the intersection between LLMs and databases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# test query\n",
    "query = \"Neural networks for image recognition\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
