{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-cloud-storage --quiet\n",
    "! pip install langchain_community --quiet\n",
    "! pip install langchain_huggingface --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded chroma_db/4d8e52f2-6027-41ef-b06b-77f96cb894fa/data_level0.bin to ./local_chromadb/4d8e52f2-6027-41ef-b06b-77f96cb894fa/data_level0.bin\n",
      "Downloaded chroma_db/4d8e52f2-6027-41ef-b06b-77f96cb894fa/header.bin to ./local_chromadb/4d8e52f2-6027-41ef-b06b-77f96cb894fa/header.bin\n",
      "Downloaded chroma_db/4d8e52f2-6027-41ef-b06b-77f96cb894fa/index_metadata.pickle to ./local_chromadb/4d8e52f2-6027-41ef-b06b-77f96cb894fa/index_metadata.pickle\n",
      "Downloaded chroma_db/4d8e52f2-6027-41ef-b06b-77f96cb894fa/length.bin to ./local_chromadb/4d8e52f2-6027-41ef-b06b-77f96cb894fa/length.bin\n",
      "Downloaded chroma_db/4d8e52f2-6027-41ef-b06b-77f96cb894fa/link_lists.bin to ./local_chromadb/4d8e52f2-6027-41ef-b06b-77f96cb894fa/link_lists.bin\n",
      "Downloaded chroma_db/chroma.sqlite3 to ./local_chromadb/chroma.sqlite3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "BUCKET_NAME = \"bucket_arxiv_researcher\"\n",
    "GCS_PERSIST_PATH = \"chroma_db/\"\n",
    "LOCAL_PERSIST_PATH = \"./local_chromadb/\"\n",
    "'''\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "BUCKET_NAME = \"arxiv-researcher-bucket\"\n",
    "GCS_PERSIST_PATH = \"chroma_db/\"\n",
    "LOCAL_PERSIST_PATH = \"./local_chromadb/\"\n",
    "\n",
    "# Initialize GCS client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "def download_directory_from_gcs(gcs_directory, local_directory, bucket_name):\n",
    "    \"\"\"Download all files from a GCS directory to a local directory.\"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=gcs_directory)\n",
    "\n",
    "    for blob in blobs:\n",
    "        if not blob.name.endswith(\"/\"):  # Avoid directory blobs\n",
    "            relative_path = os.path.relpath(blob.name, gcs_directory)\n",
    "            local_file_path = os.path.join(local_directory, relative_path)\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "            blob.download_to_filename(local_file_path)\n",
    "            print(f\"Downloaded {blob.name} to {local_file_path}\")\n",
    "\n",
    "# Download Chroma persisted data from GCS to local directory\n",
    "download_directory_from_gcs(GCS_PERSIST_PATH, LOCAL_PERSIST_PATH, BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barilanne076/.pyenv/versions/arxiv_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_76856/1858947881.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=LOCAL_PERSIST_PATH, embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-mpnet-base-v2'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "# Load the stored vector database\n",
    "db = Chroma(persist_directory=LOCAL_PERSIST_PATH, embedding_function=embeddings)\n",
    "\n",
    "# Now use db for retrieval\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76856/3401521775.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "comparing robustness of pairwise and multiclass neuralnetwork systems\n",
      "  for face recognition   noise corruptions and variations in face images can seriously hurt the\n",
      "performance of face recognition systems to make such systems robust\n",
      "multiclass neuralnetwork classifiers capable of learning from noisy data have\n",
      "been suggested however on large face data sets such systems cannot provide the\n",
      "robustness at a high level in this paper we explore a pairwise neuralnetwork\n",
      "system as an alternative approach to improving the robustness of face\n",
      "recognition in our experiments this approach is shown to outperform the\n",
      "multiclass neuralnetwork system in terms of the predictive accuracy on the\n",
      "face images corrupted by noise\n",
      "\n",
      "{'id': '0704.3515', 'year': '2007'}\n",
      "\n",
      "\n",
      "2\n",
      "the parameterless selforganizing map algorithm   the parameterless selforganizing map plsom is a new neural network\n",
      "algorithm based on the selforganizing map som it eliminates the need for a\n",
      "learning rate and annealing schemes for learning rate and neighbourhood size\n",
      "we discuss the relative performance of the plsom and the som and demonstrate\n",
      "some tasks in which the som fails but the plsom performs satisfactory finally\n",
      "we discuss some example applications of the plsom and present a proof of\n",
      "ordering under certain limited conditions\n",
      "\n",
      "{'id': '0705.0199', 'year': '2007'}\n",
      "\n",
      "\n",
      "3\n",
      "exploiting heavy tails in training times of multilayer perceptrons a\n",
      "  case study with the uci thyroid disease database   the random initialization of weights of a multilayer perceptron makes it\n",
      "possible to model its training process as a las vegas algorithm ie a\n",
      "randomized algorithm which stops when some required training error is obtained\n",
      "and whose execution time is a random variable this modeling is used to perform\n",
      "a case study on a wellknown pattern recognition benchmark the uci thyroid\n",
      "disease database empirical evidence is presented of the training time\n",
      "probability distribution exhibiting a heavy tail behavior meaning a big\n",
      "probability mass of long executions this fact is exploited to reduce the\n",
      "training time cost by applying two simple restart strategies the first assumes\n",
      "full knowledge of the distribution yielding a 40 cut down in expected time\n",
      "with respect to the training without restarts the second assumes null\n",
      "knowledge yielding a reduction ranging from 9 to 23\n",
      "\n",
      "{'id': '0704.2725', 'year': '2007'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Neural networks for image recognition\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "i = 1\n",
    "for doc in retrieved_docs:\n",
    "    print(i)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
