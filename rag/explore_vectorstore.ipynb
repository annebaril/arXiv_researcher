{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88178/3081848991.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
      "/home/barilanne076/.pyenv/versions/arxiv_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_88178/3081848991.py:24: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=LOCAL_PERSIST_PATH, embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "BUCKET_NAME = \"arxiv-researcher-bucket\"\n",
    "GCS_PERSIST_PATH = \"chroma_db/\"\n",
    "LOCAL_PERSIST_PATH = \"./local_chromadb/\"\n",
    "\n",
    "# Embedding model \n",
    "embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "def get_vectorstore(gcs_directory=GCS_PERSIST_PATH, local_directory=LOCAL_PERSIST_PATH, bucket_name=BUCKET_NAME):\n",
    "    # Initialize GCS client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=gcs_directory)\n",
    "\n",
    "    # Download Chroma persisted data from GCS to local directory\n",
    "    for blob in blobs:\n",
    "        if not blob.name.endswith(\"/\"):  # Avoid directory blobs\n",
    "            relative_path = os.path.relpath(blob.name, gcs_directory)\n",
    "            local_file_path = os.path.join(local_directory, relative_path)\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "            blob.download_to_filename(local_file_path)\n",
    "\n",
    "    # Load the stored vector database\n",
    "    vectorstore = Chroma(persist_directory=LOCAL_PERSIST_PATH, embedding_function=embeddings)\n",
    "\n",
    "    # Retrieve all stored documents\n",
    "    return vectorstore\n",
    "\n",
    "vectorstore = get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88178/3152430233.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "comparing robustness of pairwise and multiclass neuralnetwork systems\n",
      "  for face recognition   noise corruptions and variations in face images can seriously hurt the\n",
      "performance of face recognition systems to make such systems robust\n",
      "multiclass neuralnetwork classifiers capable of learning from noisy data have\n",
      "been suggested however on large face data sets such systems cannot provide the\n",
      "robustness at a high level in this paper we explore a pairwise neuralnetwork\n",
      "system as an alternative approach to improving the robustness of face\n",
      "recognition in our experiments this approach is shown to outperform the\n",
      "multiclass neuralnetwork system in terms of the predictive accuracy on the\n",
      "face images corrupted by noise\n",
      "\n",
      "{'id': '0704.3515', 'year': '2007'}\n",
      "\n",
      "\n",
      "2\n",
      "the parameterless selforganizing map algorithm   the parameterless selforganizing map plsom is a new neural network\n",
      "algorithm based on the selforganizing map som it eliminates the need for a\n",
      "learning rate and annealing schemes for learning rate and neighbourhood size\n",
      "we discuss the relative performance of the plsom and the som and demonstrate\n",
      "some tasks in which the som fails but the plsom performs satisfactory finally\n",
      "we discuss some example applications of the plsom and present a proof of\n",
      "ordering under certain limited conditions\n",
      "\n",
      "{'id': '0705.0199', 'year': '2007'}\n",
      "\n",
      "\n",
      "3\n",
      "exploiting heavy tails in training times of multilayer perceptrons a\n",
      "  case study with the uci thyroid disease database   the random initialization of weights of a multilayer perceptron makes it\n",
      "possible to model its training process as a las vegas algorithm ie a\n",
      "randomized algorithm which stops when some required training error is obtained\n",
      "and whose execution time is a random variable this modeling is used to perform\n",
      "a case study on a wellknown pattern recognition benchmark the uci thyroid\n",
      "disease database empirical evidence is presented of the training time\n",
      "probability distribution exhibiting a heavy tail behavior meaning a big\n",
      "probability mass of long executions this fact is exploited to reduce the\n",
      "training time cost by applying two simple restart strategies the first assumes\n",
      "full knowledge of the distribution yielding a 40 cut down in expected time\n",
      "with respect to the training without restarts the second assumes null\n",
      "knowledge yielding a reduction ranging from 9 to 23\n",
      "\n",
      "{'id': '0704.2725', 'year': '2007'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "query = \"Neural networks for image recognition\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "i = 1\n",
    "for doc in retrieved_docs:\n",
    "    print(i)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    "    task=\"text-generation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barilanne076/.pyenv/versions/arxiv_env/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['query', 'result'])\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "query1 = \"Which articles use LLM in Finance, and return back the id and metadata of this article\"\n",
    "response1 = qa_chain.invoke(query1)\n",
    "print(response1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which articles use LLM in Finance, and return back the id and metadata of this article'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the context provided, it seems that the articles discussed in the texts are related to the use of access data and digital libraries for paper recommendations. However, none of the articles mention LLM in Finance specifically. Therefore, I cannot provide you with the id and metadata of articles that use LLM in Finance based on this context.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
